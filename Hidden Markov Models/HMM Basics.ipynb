{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ('Rainy', 'Sunny')\n",
    "observations = ('walk', 'shop', 'clean')\n",
    "pi = np.array([0.6, 0.4])  #initial probability \n",
    "A = np.array([[0.7, 0.3],[0.4, 0.6]]) #Transmission probability \n",
    "B = np.array([[0.1, 0.4, 0.5],[0.6, 0.3, 0.1]]) #Emission probability\n",
    "bob_says = np.array([0, 2, 1, 1, 2, 0, 1,2,1,0,0,2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(obs_seq, pi, A, B):\n",
    "    T = len(obs_seq)\n",
    "    N = A.shape[0]\n",
    "    alpha = np.zeros((T, N))\n",
    "    alpha[0] = pi*B[:,obs_seq[0]]\n",
    "    for t in range(1, T):\n",
    "        alpha[t] = np.inner(alpha[t-1],A) * B[:, obs_seq[t]]\n",
    "    return alpha\n",
    "\n",
    "def likelihood(alpha):\n",
    "    # returns log P(Y  \\mid  model)\n",
    "    # using the forward part of the forward-backward algorithm\n",
    "    return  alpha[-1].sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.00000000e-02   2.40000000e-01]\n",
      " [  5.70000000e-02   1.68000000e-02]\n",
      " [  1.79760000e-02   9.86400000e-03]\n",
      " [  6.21696000e-03   3.93264000e-03]\n",
      " [  2.76583200e-03   4.84636800e-04]\n",
      " [  2.08147344e-04   8.38268928e-04]\n",
      " [  1.58873528e-04   1.75866088e-04]\n",
      " [  8.19856479e-05   1.69069064e-05]\n",
      " [  2.49848102e-05   1.28815209e-05]\n",
      " [  2.13538234e-06   1.06337020e-05]\n",
      " [  4.68487823e-07   4.34062447e-06]\n",
      " [  8.15064409e-07   2.79176981e-07]\n",
      " [  2.61719272e-07   1.48059586e-07]]\n"
     ]
    }
   ],
   "source": [
    "alpha = forward(bob_says, pi, A, B)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0977885787645574e-07"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(obs_seq, A, B):\n",
    "    N = A.shape[0]\n",
    "    T = len(obs_seq)\n",
    "\n",
    "    beta = np.zeros((N,T))\n",
    "    beta[:,-1:] = 1\n",
    "\n",
    "    for t in reversed(range(T-1)):\n",
    "        for n in range(N):\n",
    "            beta[n,t] = np.sum(beta[:,t+1] * A[n,:] * B[:, obs_seq[t+1]])\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma(alpha, beta):\n",
    "    obs_prob = likelihood(alpha)\n",
    "    return (np.multiply(alpha,beta.T) / obs_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.06140910e-06,   1.38377453e-06],\n",
       "       [  5.47808732e-06,   4.80261779e-06],\n",
       "       [  1.53838921e-05,   1.30066392e-05],\n",
       "       [  4.44028627e-05,   3.27898953e-05],\n",
       "       [  1.12031660e-04,   1.73059389e-04],\n",
       "       [  5.10039314e-04,   4.24049489e-04],\n",
       "       [  1.49007285e-03,   1.03132130e-03],\n",
       "       [  3.89764880e-03,   4.19652560e-03],\n",
       "       [  8.99693000e-03,   1.53167600e-02],\n",
       "       [  2.67710000e-02,   3.95720000e-02],\n",
       "       [  1.39700000e-01,   9.44000000e-02],\n",
       "       [  3.70000000e-01,   3.40000000e-01],\n",
       "       [  1.00000000e+00,   1.00000000e+00]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta=backward(bob_says, A, B)\n",
    "beta.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30183242,  0.81045149],\n",
       "       [ 0.76199875,  0.19689639],\n",
       "       [ 0.67485386,  0.31308958],\n",
       "       [ 0.67365804,  0.31468401],\n",
       "       [ 0.75616578,  0.20467368],\n",
       "       [ 0.25907469,  0.86746181],\n",
       "       [ 0.57770948,  0.44261542],\n",
       "       [ 0.77981393,  0.17314282],\n",
       "       [ 0.54855585,  0.48148693],\n",
       "       [ 0.1395053 ,  1.02688766],\n",
       "       [ 0.1597148 ,  0.99994166],\n",
       "       [ 0.73594288,  0.23163756],\n",
       "       [ 0.63868418,  0.36131582]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma(alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(obs_seq,pi, A, B):\n",
    "    # returns the most likely state sequence given observed sequence x\n",
    "    # using the Viterbi algorithm\n",
    "    T = len(obs_seq)\n",
    "    N = A.shape[0]\n",
    "    delta = np.zeros((T, N))\n",
    "    psi = np.zeros((T, N))\n",
    "    delta[0] = pi*B[:,obs_seq[0]]\n",
    "    for t in range(1, T):\n",
    "        for j in range(N):\n",
    "            delta[t,j] = np.max(delta[t-1]*A[:,j]) * B[j, obs_seq[t]]\n",
    "            psi[t,j] = np.argmax(delta[t-1]*A[:,j])\n",
    "\n",
    "    # backtrack\n",
    "    states = np.zeros(T, dtype=np.int32)\n",
    "    states[T-1] = np.argmax(delta[T-1])\n",
    "    for t in range(T-2, -1, -1):\n",
    "        states[t] = psi[t+1, states[t+1]]\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob says: ,  ['walk', 'clean', 'shop', 'shop', 'clean', 'walk', 'shop', 'clean', 'shop', 'walk', 'walk', 'clean', 'shop']\n",
      "Alice hears: ,  ['Sunny', 'Rainy', 'Rainy', 'Rainy', 'Rainy', 'Sunny', 'Rainy', 'Rainy', 'Rainy', 'Sunny', 'Sunny', 'Rainy', 'Rainy']\n"
     ]
    }
   ],
   "source": [
    "alice_hears=viterbi(bob_says, pi, A, B)\n",
    "print(\"Bob says:\", \", \",list(map(lambda y: observations[y], bob_says)))\n",
    "print(\"Alice hears:\", \", \", list(map(lambda s: states[s], alice_hears)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_seq=torch.from_numpy(bob_says)\n",
    "pi_ = torch.from_numpy(pi).float()\n",
    "A_ = torch.from_numpy(A).float()\n",
    "B_ = torch.from_numpy(B).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(obs_seq, pi, A, B):\n",
    "    \n",
    "    T = len(obs_seq)\n",
    "    N = A.shape[0]\n",
    "    alpha = torch.empty(T, N)\n",
    "    alpha[0] = pi*B[:,obs_seq[0]]\n",
    "    for t in range(1, T):\n",
    "        alpha[t]=torch.mv(A, alpha[t-1]) * B[:, obs_seq[t]]\n",
    "    return alpha\n",
    "        \n",
    "\n",
    "\n",
    "def likelihood(alpha):\n",
    "    # returns log P(Y  \\mid  model)\n",
    "    # using the forward part of the forward-backward algorithm\n",
    "    return  alpha[-1].sum()  \n",
    "\n",
    "def backward(obs_seq, A, B):\n",
    "    N = A.shape[0]\n",
    "    T = len(obs_seq)\n",
    "\n",
    "    beta = torch.empty(N, T)\n",
    "    beta[:,-1:] = 1\n",
    "    \n",
    "\n",
    "    for t in reversed(range(T-1)):\n",
    "        for n in range(N):\n",
    "            beta[n,t] = torch.sum(beta[:,t+1] * A[n,:] * B[:, obs_seq[t+1]])\n",
    "            \n",
    "    return beta\n",
    "            \n",
    "def gamma(alpha, beta):\n",
    "    obs_prob = likelihood(alpha)\n",
    "    return (torch.mul(alpha,beta.transpose(0, 1)) / obs_prob)\n",
    "\n",
    "def viterbi(obs_seq,pi, A, B):\n",
    "    # returns the most likely state sequence given observed sequence x\n",
    "    # using the Viterbi algorithm\n",
    "    T = len(obs_seq)\n",
    "    N = A.shape[0]\n",
    "    delta = torch.zeros(T, N)\n",
    "    psi = torch.zeros(T, N)\n",
    "    delta[0] = pi*B[:,obs_seq[0]]\n",
    "    for t in range(1, T):\n",
    "        for j in range(N):\n",
    "            delta[t,j] = torch.max(delta[t-1]*A[:,j]) * B[j, obs_seq[t]]\n",
    "            psi[t,j] = torch.argmax(delta[t-1]*A[:,j])\n",
    "\n",
    "    # backtrack\n",
    "    states = torch.zeros(T).long()\n",
    "    states[T-1] = torch.argmax(delta[T-1])\n",
    "    for t in range(T-2, -1, -1):\n",
    "        states[t] = psi[t+1, states[t+1]]\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3018, 0.8105],\n",
       "        [0.7620, 0.1969],\n",
       "        [0.6749, 0.3131],\n",
       "        [0.6737, 0.3147],\n",
       "        [0.7562, 0.2047],\n",
       "        [0.2591, 0.8675],\n",
       "        [0.5777, 0.4426],\n",
       "        [0.7798, 0.1731],\n",
       "        [0.5486, 0.4815],\n",
       "        [0.1395, 1.0269],\n",
       "        [0.1597, 0.9999],\n",
       "        [0.7359, 0.2316],\n",
       "        [0.6387, 0.3613]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha= forward(obs_seq, pi_, A_, B_)\n",
    "beta =backward(obs_seq, A_, B_)\n",
    "gamma(alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob says: ,  ['walk', 'clean', 'shop', 'shop', 'clean', 'walk', 'shop', 'clean', 'shop', 'walk', 'walk', 'clean', 'shop']\n",
      "Alice hears: ,  ['Sunny', 'Rainy', 'Rainy', 'Rainy', 'Rainy', 'Sunny', 'Rainy', 'Rainy', 'Rainy', 'Sunny', 'Sunny', 'Rainy', 'Rainy']\n"
     ]
    }
   ],
   "source": [
    "alice_hears=viterbi(bob_says,pi_, A_, B_)\n",
    "print(\"Bob says:\", \", \",list(map(lambda y: observations[y], bob_says)))\n",
    "print(\"Alice hears:\", \", \", list(map(lambda s: states[s], alice_hears.numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DHMM(torch.nn.Module):\n",
    "    def __init__(self, M=2, T=10,pi=None, A=None, B=None):\n",
    "        self.M = M \n",
    "        self.T = T\n",
    "        if pi is None:\n",
    "            self.initilize()\n",
    "        else:\n",
    "            self.pi=pi\n",
    "            self.A=A\n",
    "            self.B=B\n",
    "        super(DHMM, self).__init__()\n",
    "        \n",
    "    def random_normalized(self, d1, d2):\n",
    "        x = torch.rand(d1, d2)\n",
    "        return x / x.sum()\n",
    "    \n",
    "    def initilize(self):\n",
    "        self.pi = torch.ones(self.M) / self.M\n",
    "        self.A = self.random_normalized(self.M, self.M)\n",
    "        self.B = self.random_normalized(self.M, self.T)\n",
    "        \n",
    "        \n",
    "    def forward_path(self, obs_seq):\n",
    "        \n",
    "        alpha = torch.empty(self.T, self.M)\n",
    "        scale = torch.empty(self.T)\n",
    "        alpha[0] = self.pi*self.B[:,obs_seq[0]]\n",
    "        scale[0] = alpha[0].sum()\n",
    "        alpha[0] /= scale[0]\n",
    "        for t in range(1, self.T):\n",
    "            alpha[t]=torch.mv(self.A, alpha[t-1]) * self.B[:, obs_seq[t]]\n",
    "            scale[t] = alpha[t].sum()\n",
    "            alpha[t] /= scale[t]\n",
    "            \n",
    "        return alpha, scale\n",
    "    \n",
    "    def backward_path(self, obs_seq, scale):\n",
    "        \n",
    "        beta = torch.empty(self.M, self.T)\n",
    "        beta[:,-1:] = 1\n",
    "        \n",
    "        for t in reversed(range(self.T-1)):\n",
    "            for m in range(self.M):\n",
    "                beta[m,t] = torch.sum(beta[:,t+1] * self.A[m,:] * self.B[:, obs_seq[t+1]]/scale[t+1])\n",
    "        return beta\n",
    "    \n",
    "    def likelihood(self, scale):\n",
    "        return  torch.log(scale).sum()\n",
    "    \n",
    "    def forward_backward(self, obs_seq):\n",
    "        \n",
    "        alpha, scale=self.forward_path(obs_seq)\n",
    "        beta  = self.backward_path(obs_seq, scale)\n",
    "        obs_prob = self.likelihood(alpha)\n",
    "        return (torch.mul(alpha,beta.transpose(0, 1)) / obs_prob)\n",
    "    \n",
    "    def fit(self, obs_seq):\n",
    "        alpha, scale=self.forward_path(obs_seq)\n",
    "        beta  = self.backward_path(obs_seq, scale)\n",
    "        beta  = beta.transpose(0, 1)\n",
    "        x=torch.stack([alpha[n][0] * beta[n][0] for n in range(self.M)])\n",
    "        print(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-14.7076)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = len(obs_seq)\n",
    "hmm = DHMM(M=2,T=T, pi=pi_, A=A_, B=B_)\n",
    "alpha, scale=hmm.forward_path(obs_seq)\n",
    "beta = hmm.backward_path(obs_seq, scale)\n",
    "hmm.forward_backward(obs_seq)\n",
    "hmm.likelihood(scale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
